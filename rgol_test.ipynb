{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rgol_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPUiD3JsWbPDrXAVBuKyrnO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ImanariRoll/kaggleRGOL/blob/master/rgol_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENjMX5vUshbh",
        "outputId": "1634298a-767e-4a60-8dc0-42e99259c6f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My\\ Drive/rgol"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/rgol\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV3IqiFZRF8d"
      },
      "source": [
        "# run in console to prevent timeout\n",
        "function ClickConnect() {\n",
        "  console.log('Working')\n",
        "  document\n",
        "    .querySelector('#top-toolbar > colab-connect-button')\n",
        "    .shadowRoot.querySelector('#connect')\n",
        "    .click()\n",
        "}\n",
        "\n",
        "setInterval(ClickConnect, 60000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkOfXeYetf6A"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import keras as ks\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Conv2DTranspose, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn3XcCM3udiV"
      },
      "source": [
        "# LOAD DATA\n",
        "train_df = pd.read_csv('data/train.csv', index_col=0)\n",
        "test_df = pd.read_csv('data/test.csv', index_col=0)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMo31YQIuTuu"
      },
      "source": [
        "\n",
        "\n",
        "# my generators\n",
        "moore = [(-1, -1), (-1, 0), (-1, 1),\\\n",
        "            (0, -1), (0, 1),\\\n",
        "            (1, -1), (1, 0), (1, 1)]\n",
        "\n",
        "def evolve(X, K, S, B):\n",
        "    \"\"\"Return the next cellular automaton state.\"\"\"\n",
        "    adjacent = np.zeros(X.shape)\n",
        "    for i, j in K:\n",
        "        adjacent += np.roll(X, [i, j], [0, 1])\n",
        "        \n",
        "    next_state = np.where(X, np.isin(adjacent, S), np.isin(adjacent, B))\n",
        "    return next_state + 0\n",
        "\n",
        "def golgen(state):\n",
        "    \"\"\"Conway's Game of Life cellular automaton generator.\"\"\"\n",
        "    while True:\n",
        "        state = evolve(state, moore, [2, 3], [3])\n",
        "        yield state\n",
        "        \n",
        "# my make_move function\n",
        "def make_move(state, moves):\n",
        "    gen = golgen(state)\n",
        "    for _ in range(moves):\n",
        "        state = next(gen)\n",
        "        \n",
        "    return state\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AMfWp5FuXtz"
      },
      "source": [
        "# original author's generators\n",
        "NROW, NCOL = 25, 25\n",
        "\n",
        "def generate_samples(delta=1, n=32):\n",
        "    \"\"\"\n",
        "    Generate batch of samples\n",
        "    \n",
        "    @return: (end_frames, start_frames)\n",
        "    \"\"\"\n",
        "    # uint8 is an 8-bit unsigned integer\n",
        "    # split into n batches of NROWxNCOL grids\n",
        "    batch = np.split(np.random.binomial(1, 0.5, (NROW * n, NCOL)).astype('uint8'), n)\n",
        "    Yy = [life.make_move(state, 5) for state in batch] # transition each state in batch\n",
        "    # is this because we want to learn actual gol states, not just random starting states?\n",
        "    Xx = [life.make_move(state, 1) for state in Yy] # transition each state in batch \n",
        "    Y = np.array([y.ravel() for y in Yy])\n",
        "    X = np.array([x.ravel() for x in Xx])\n",
        "    return X, Y\n",
        "    \n",
        "# this is the same function writen as a generator\n",
        "def data_generator(delta=1, batch_size=32, ravel=True):\n",
        "    \"\"\"\n",
        "    Can be used along with .fit_generator to generate training samples on the fly\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        batch = np.split(np.random.binomial(1, 0.5, (NROW * batch_size, NCOL)).astype('uint8'), batch_size)\n",
        "        Yy = [make_move(state, 5) for state in batch]\n",
        "        Xx = [make_move(state, 5 + delta) for state in Yy]\n",
        "\n",
        "        if ravel:\n",
        "            # turn grids into 1D\n",
        "            Y = np.array([y.ravel() for y in Yy])\n",
        "            X = np.array([x.ravel() for x in Xx])\n",
        "            yield X, Y\n",
        "        else:\n",
        "            yield np.array(Xx)[:,:, :, np.newaxis], np.array(Yy)[:, :, :, np.newaxis]\n",
        "            \n",
        "def create_model(n_hidden_convs=2, n_hidden_filters=128, kernel_size=5):\n",
        "    nn = Sequential()\n",
        "    # hidden filters, kernel size, padding, activation?\n",
        "    nn.add(Conv2D(n_hidden_filters, kernel_size, padding='same', activation='relu', input_shape=(25, 25, 1)))\n",
        "    # what is batch normalization?\n",
        "    nn.add(BatchNormalization())\n",
        "    for i in range(n_hidden_convs):\n",
        "        nn.add(Conv2D(n_hidden_filters, kernel_size, padding='same', activation='relu'))\n",
        "        nn.add(BatchNormalization())\n",
        "    nn.add(Conv2D(1, kernel_size, padding='same', activation='sigmoid'))\n",
        "    nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return nn"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IriSUcyDqnV_"
      },
      "source": [
        "# set up system for working with saved models\n",
        "#   function that loads models and outputs a list of them\n",
        "\n",
        "# save models\n",
        "def save_models():\n",
        "  for i in range(5):\n",
        "    models[i].save(f'model{i}')\n",
        "\n",
        "# load models\n",
        "def load_models():\n",
        "  models = []\n",
        "  for i in range(5):\n",
        "    models.append(keras.models.load_model(f'model{i}'))\n",
        "  return models \n",
        " "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o17DYXl-ubNp",
        "outputId": "98378ed0-f22e-4200-9888-0b9d65ba4110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# TRAIN THE MODELS\n",
        "models = []\n",
        "for delta in range(1, 6):\n",
        "    model = create_model(n_hidden_convs=6, n_hidden_filters=512)\n",
        "    es = EarlyStopping(monitor='loss', patience=9, min_delta=0.001)\n",
        "    model.fit(data_generator(delta=delta, ravel=False), steps_per_epoch=500, epochs=50, verbose=1, callbacks=[es])\n",
        "    models.append(model)\n",
        "    \n",
        "   "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "  2/500 [..............................] - ETA: 54s - loss: 1.9769 - accuracy: 0.5114WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0714s vs `on_train_batch_end` time: 0.1467s). Check your callbacks.\n",
            "500/500 [==============================] - 116s 232ms/step - loss: 0.5715 - accuracy: 0.7549\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 122s 244ms/step - loss: 0.5320 - accuracy: 0.7656\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 122s 243ms/step - loss: 0.5303 - accuracy: 0.7668\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 122s 244ms/step - loss: 0.5313 - accuracy: 0.7659\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5307 - accuracy: 0.7667\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5285 - accuracy: 0.7673\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5271 - accuracy: 0.7672\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5249 - accuracy: 0.7677\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5242 - accuracy: 0.7679\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5248 - accuracy: 0.7676\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5243 - accuracy: 0.7679\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5233 - accuracy: 0.7682\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5211 - accuracy: 0.7685\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5222 - accuracy: 0.7675\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5206 - accuracy: 0.7682\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5205 - accuracy: 0.7682\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5202 - accuracy: 0.7682\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5206 - accuracy: 0.7678\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5204 - accuracy: 0.7681\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5204 - accuracy: 0.7679\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5199 - accuracy: 0.7682\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5193 - accuracy: 0.7685\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5198 - accuracy: 0.7682\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5202 - accuracy: 0.7679\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5197 - accuracy: 0.7682\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5204 - accuracy: 0.7678\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5260 - accuracy: 0.7675\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5225 - accuracy: 0.7675\n",
            "Epoch 29/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5209 - accuracy: 0.7680\n",
            "Epoch 30/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5202 - accuracy: 0.7684\n",
            "Epoch 1/50\n",
            "  2/500 [..............................] - ETA: 59s - loss: 1.8109 - accuracy: 0.5255WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0781s vs `on_train_batch_end` time: 0.1609s). Check your callbacks.\n",
            "500/500 [==============================] - 122s 244ms/step - loss: 0.5692 - accuracy: 0.7551\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 122s 243ms/step - loss: 0.5375 - accuracy: 0.7652\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 122s 243ms/step - loss: 0.5361 - accuracy: 0.7668\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 122s 243ms/step - loss: 0.5344 - accuracy: 0.7668\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5330 - accuracy: 0.7677\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5338 - accuracy: 0.7668\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5310 - accuracy: 0.7676\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5306 - accuracy: 0.7673\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5297 - accuracy: 0.7676\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5304 - accuracy: 0.7675\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5292 - accuracy: 0.7676\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5311 - accuracy: 0.7676\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5274 - accuracy: 0.7681\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5265 - accuracy: 0.7681\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5265 - accuracy: 0.7680\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5255 - accuracy: 0.7682\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5253 - accuracy: 0.7682\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5252 - accuracy: 0.7683\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5250 - accuracy: 0.7685\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5258 - accuracy: 0.7677\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5249 - accuracy: 0.7683\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5249 - accuracy: 0.7681\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5243 - accuracy: 0.7685\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5245 - accuracy: 0.7683\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5246 - accuracy: 0.7684\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5253 - accuracy: 0.7677\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5248 - accuracy: 0.7680\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5250 - accuracy: 0.7678\n",
            "Epoch 29/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5244 - accuracy: 0.7683\n",
            "Epoch 30/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5247 - accuracy: 0.7681\n",
            "Epoch 31/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5244 - accuracy: 0.7681\n",
            "Epoch 32/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5246 - accuracy: 0.7680\n",
            "Epoch 1/50\n",
            "  2/500 [..............................] - ETA: 1:00 - loss: 2.3847 - accuracy: 0.5787WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0810s vs `on_train_batch_end` time: 0.1610s). Check your callbacks.\n",
            "500/500 [==============================] - 122s 243ms/step - loss: 0.5770 - accuracy: 0.7543\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 122s 243ms/step - loss: 0.5377 - accuracy: 0.7670\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5393 - accuracy: 0.7660\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5372 - accuracy: 0.7668\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5353 - accuracy: 0.7675\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5346 - accuracy: 0.7675\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5344 - accuracy: 0.7676\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5337 - accuracy: 0.7677\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5338 - accuracy: 0.7673\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5346 - accuracy: 0.7675\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5334 - accuracy: 0.7673\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5335 - accuracy: 0.7675\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5308 - accuracy: 0.7683\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5319 - accuracy: 0.7677\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5325 - accuracy: 0.7677\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5304 - accuracy: 0.7679\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5299 - accuracy: 0.7679\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5295 - accuracy: 0.7678\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5293 - accuracy: 0.7679\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5287 - accuracy: 0.7681\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 120s 239ms/step - loss: 0.5288 - accuracy: 0.7680\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5288 - accuracy: 0.7679\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5285 - accuracy: 0.7681\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 120s 239ms/step - loss: 0.5286 - accuracy: 0.7680\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5282 - accuracy: 0.7683\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 120s 239ms/step - loss: 0.5288 - accuracy: 0.7678\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5280 - accuracy: 0.7682\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 120s 239ms/step - loss: 0.5284 - accuracy: 0.7680\n",
            "Epoch 29/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5277 - accuracy: 0.7685\n",
            "Epoch 30/50\n",
            "500/500 [==============================] - 120s 239ms/step - loss: 0.5284 - accuracy: 0.7679\n",
            "Epoch 31/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5289 - accuracy: 0.7682\n",
            "Epoch 32/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5282 - accuracy: 0.7682\n",
            "Epoch 1/50\n",
            "  2/500 [..............................] - ETA: 1:00 - loss: 1.9269 - accuracy: 0.5341WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0812s vs `on_train_batch_end` time: 0.1599s). Check your callbacks.\n",
            "500/500 [==============================] - 122s 244ms/step - loss: 0.5784 - accuracy: 0.7539\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 122s 243ms/step - loss: 0.5434 - accuracy: 0.7660\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 122s 243ms/step - loss: 0.5426 - accuracy: 0.7670\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5418 - accuracy: 0.7671\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5413 - accuracy: 0.7672\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5382 - accuracy: 0.7674\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5372 - accuracy: 0.7677\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5363 - accuracy: 0.7674\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5346 - accuracy: 0.7678\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5399 - accuracy: 0.7674\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5351 - accuracy: 0.7673\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5329 - accuracy: 0.7682\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5326 - accuracy: 0.7679\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5325 - accuracy: 0.7677\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5323 - accuracy: 0.7677\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5318 - accuracy: 0.7680\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5321 - accuracy: 0.7676\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5320 - accuracy: 0.7678\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5315 - accuracy: 0.7680\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5316 - accuracy: 0.7679\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5312 - accuracy: 0.7682\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5311 - accuracy: 0.7681\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5318 - accuracy: 0.7677\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5311 - accuracy: 0.7681\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5315 - accuracy: 0.7678\n",
            "Epoch 1/50\n",
            "  2/500 [..............................] - ETA: 1:00 - loss: 1.9157 - accuracy: 0.5188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0834s vs `on_train_batch_end` time: 0.1586s). Check your callbacks.\n",
            "500/500 [==============================] - 122s 243ms/step - loss: 0.5785 - accuracy: 0.7551\n",
            "Epoch 2/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5430 - accuracy: 0.7663\n",
            "Epoch 3/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5442 - accuracy: 0.7662\n",
            "Epoch 4/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5428 - accuracy: 0.7666\n",
            "Epoch 5/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5438 - accuracy: 0.7658\n",
            "Epoch 6/50\n",
            "500/500 [==============================] - 121s 243ms/step - loss: 0.5415 - accuracy: 0.7668\n",
            "Epoch 7/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5419 - accuracy: 0.7667\n",
            "Epoch 8/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5393 - accuracy: 0.7678\n",
            "Epoch 9/50\n",
            "500/500 [==============================] - 121s 242ms/step - loss: 0.5381 - accuracy: 0.7678\n",
            "Epoch 10/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5384 - accuracy: 0.7674\n",
            "Epoch 11/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5365 - accuracy: 0.7680\n",
            "Epoch 12/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5368 - accuracy: 0.7679\n",
            "Epoch 13/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5368 - accuracy: 0.7677\n",
            "Epoch 14/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5353 - accuracy: 0.7680\n",
            "Epoch 15/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5343 - accuracy: 0.7681\n",
            "Epoch 16/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5345 - accuracy: 0.7678\n",
            "Epoch 17/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5338 - accuracy: 0.7680\n",
            "Epoch 18/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5331 - accuracy: 0.7685\n",
            "Epoch 19/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5334 - accuracy: 0.7682\n",
            "Epoch 20/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5335 - accuracy: 0.7680\n",
            "Epoch 21/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5332 - accuracy: 0.7681\n",
            "Epoch 22/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5336 - accuracy: 0.7681\n",
            "Epoch 23/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5327 - accuracy: 0.7686\n",
            "Epoch 24/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5333 - accuracy: 0.7680\n",
            "Epoch 25/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5338 - accuracy: 0.7677\n",
            "Epoch 26/50\n",
            "500/500 [==============================] - 120s 239ms/step - loss: 0.5331 - accuracy: 0.7681\n",
            "Epoch 27/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5340 - accuracy: 0.7675\n",
            "Epoch 28/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5328 - accuracy: 0.7683\n",
            "Epoch 29/50\n",
            "500/500 [==============================] - 120s 240ms/step - loss: 0.5344 - accuracy: 0.7679\n",
            "Epoch 30/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5343 - accuracy: 0.7675\n",
            "Epoch 31/50\n",
            "500/500 [==============================] - 120s 241ms/step - loss: 0.5322 - accuracy: 0.7688\n",
            "Epoch 32/50\n",
            "500/500 [==============================] - 121s 241ms/step - loss: 0.5333 - accuracy: 0.7680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54uwuGPYLkPs",
        "outputId": "fc44b787-1302-44c9-d527-18afd9c4a30c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# GOD SAVE THE MODELS!!!\n",
        "save_models()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: model0/assets\n",
            "INFO:tensorflow:Assets written to: model1/assets\n",
            "INFO:tensorflow:Assets written to: model2/assets\n",
            "INFO:tensorflow:Assets written to: model3/assets\n",
            "INFO:tensorflow:Assets written to: model4/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KyZgX1GeC3o"
      },
      "source": [
        "# test model with images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcommHYRlBnS",
        "outputId": "a72ce1fb-bfc1-4a2e-acec-b8964e6ade7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "fig, ax = plt.subplots()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t5aMYqLNrni"
      },
      "source": [
        "def get_prediction(delta):\n",
        "  # must have shape (-1, 25, 25, 1) for keras predict. (-1, 25, 25) for imshow\n",
        "  start = train_df[train_df.delta == delta].iloc[:, 1:626].values.reshape(-1, 25, 25)\n",
        "  stop = train_df[train_df.delta == delta].iloc[:, 626:].values.reshape(-1, 25, 25, 1)\n",
        "  predicted_start = models[delta-1].predict(stop).reshape(-1, 25, 25)\n",
        "  stop = stop.reshape(-1, 25, 25)\n",
        "  return start, stop, predicted_start"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9lweUCjDYOT"
      },
      "source": [
        "datasets = get_prediction(5)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPWCcrBiA8bG",
        "outputId": "687091dc-8bdc-4fea-c561-c7cb3daddc29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        }
      },
      "source": [
        "n = 10\n",
        "for ds in datasets:\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.imshow(ds[n])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARa0lEQVR4nO3dW4xd1XkH8P//XObiyzg2F9dgUyCx1Fqq4hALpQ2tTKNGJFVl8oKCqsoPkZwHqIiUFysv5KVSXkiqVCiSIyz8kBAhJQRLpQXkpnJSVREDdcCEECxqiq2xJ2Dj21zPOV8fZhtNnDnrWz5nz7nw/X+SNWfOXrP3Otv7P/vMrG/WoplBRD76Kv3ugIj0hsIuEoTCLhKEwi4ShMIuEkStlwcbqY7beG0i3YhMb88ZPKg4+xApm3fdZjLn2rVaevvczHksLlxZsVFPwz5em8Bf3PL3yTZWT3eJjaZ7HBsf9TtTyXhT06thyZIuFOkfq2b8H2b8P7dG09f//I1jye3/84vvtt3W1dt4kveRfJPkCZL7u9mXiKyujsNOsgrgcQBfALADwIMkd5TVMREpVzd39rsBnDCzt81sAcCPAOwpp1siUrZuwn4rgHeXfX6qeO73kNxHcpLk5EJztovDiUg3Vn3ozcwOmNkuM9s1Uh1f7cOJSBvdhP00gG3LPt9aPCciA6ibsL8EYDvJO0iOAPgygMPldEtEytbxOLuZNUg+DOB5AFUAB83s9eQXkUC1mm5yeSZ93EbD7VvWqLXGtuWqMq6FWvq6BgBU/XtrxantGDmf3gcb7b++q6IaM3sOwHPd7ENEekO18SJBKOwiQSjsIkEo7CJBKOwiQSjsIkH09O/ZYQY003+PbouL6e0L6e0A3LF8AGDG2Kqm2R5sOf+HJR3IbzJS9/fTbPlt1qZLyqvOPAxstb9mdWcXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQmEXCUJhFwmix0U1AJxFHlh3ihMW/ckrMD/vNmnlFDi0MtoMk5yFMYZIWSVPbnFOzgpDOddKouDlw754k2B4hV4qqhERhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kiN4W1eSoOV3KKHCwnIIZZ0ac7P2UIadoQ1aPW1Tj3xPJku6bTtEZ6l5kVVQjEp7CLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhJEb4tqKhWYs7yNh42cmWoW3CbeMlNLjXpUVOPUUaCsgg1ZkTmnlzmz0JR1rTjLo7kz1SR0FXaSJwFcwtLl2jCzXd3sT0RWTxl39nvN7L0S9iMiq0jvD0WC6DbsBuAFki+T3LdSA5L7SE6SnFxoznR5OBHpVLdv4+8xs9MkbwbwIsnfmNnR5Q3M7ACAAwCwYWyLFjwX6ZOu7uxmdrr4OA3gGQB3l9EpESlfx2EnuZbk+quPAXwewPGyOiYi5ermbfxmAM8Uq2nUAPzQzP499QVWq6Bxw7rkTulMGFHNGvPM+GlhIWMsfsEZiy9rbNUdR/cG4mNiWZN+tNLn3xuHBwBmrPZiGdel94pyjtNOx2E3s7cBfLLjI4tIT2noTSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSSInk5e0Ryr4MIn1iTbVJrpooH1/+t/f8p6UZev+G28opmc4h1vtZGc42jyihVZFwUmy7HinH+n6AbIK5jJUtZ+VqCrSCQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kiJ4W1TTWGqY/m5515RPbp5Lb3z26zT3Obc/7hQnVS35RDefnk9stZ3WaMvRqZZqPIhUkfUhnQiQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSSIno6z37z+Ih75yxeSbf7xY28ntz8y8efucX712k63zcTUqNuGtfTpKWvyhFJoLF4curOLBKGwiwShsIsEobCLBKGwiwShsIsEobCLBKGwiwTR06Ka6Zn1+JdX7k22mflkutjl+f+4yz3O7e/P+Z1ppCfRAABU0t8LWfFXexmowhsJTXd2kSDcsJM8SHKa5PFlz20i+SLJt4qPG1e3myLSrZw7+5MA7rvmuf0AjpjZdgBHis9FZIC5YTezowDOXfP0HgCHiseHANxfcr9EpGSd/sy+2cyuTgN7BsDmdg1J7iM5SXKyeTFjmWQRWRVd/4LOlhambvsrZzM7YGa7zGxXdWJtt4cTkQ51GvazJLcAQPFxurwuichq6DTshwHsLR7vBfBsOd0RkdXiFtWQfArAbgA3kjwF4FEA3wLwNMmvAHgHwANZB7tQwc3/li6a+emRv05u33ZqwT/O+Vm3jS0sum1cGauNsOLPIKPCmw4N2WovpF+EhWo1udmqnb9mN+xm9mCbTZ/r+Kgi0nPD9a1RRDqmsIsEobCLBKGwiwShsIsEobCLBKGwiwTR05lqqgstrH/HmUXGKTCpXfALZjjjz1RjGbPMeMs/oZVRMNPQskwdKalgJmc2IfdYOddKTrFLzmuqpYtq3O2Jwh3d2UWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWC6Ok4OwzuOLq7C2eVFgDASN1twmbOGHkj3aCZsaqM+a+XSO8na3KLsiZysB7VBZTQ31LG0AF3HJ3OhBIA3EknAIB1/7q0sfTkLq01I+mvT7wW3dlFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYLoaVGNVYjmmvQhrZoucLCa//2pOucXL1S8SQAAZJRs+Gb9ghivaKanq8p4RSg5RTdDVDAD+EUz7iQmADg25rax8XTBDAC01qf301ifLqpBYhIN3dlFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYLoaVFNq05c2ZIueGk5RTWVht/l+qxTeABg5IOMNk4BTyVjFpqc2WzMa5MxIU5OEUophTe9XKnFU0LBDJBRNDPqF8PYGr+opvWxtW6bhY3pY81tTPe1VetiphqSB0lOkzy+7LlvkjxN8ljx74vefkSkv3K+TT8J4L4Vnv+Ome0s/j1XbrdEpGxu2M3sKIBzPeiLiKyibn4Ae5jkq8Xb/I3tGpHcR3KS5GRj/koXhxORbnQa9u8B+DiAnQCmADzWrqGZHTCzXWa2qzbq/4JCRFZHR2E3s7Nm1jSzFoDvA7i73G6JSNk6CjvJLcs+/RKA4+3aishgcAetST4FYDeAG0meAvAogN0kd2JpjZeTAL66in0UkRK4YTezB1d4+olODtYaAS5tS7+ZaDq1CZaxEk/tiv+GZc0Zv82Es310btHvzPyC24QL6f1kFcP0atmmDKUUzGQU75AZRTUZs8x4RTNcO+7uojnht5nf5BfnzN6U7u+VP3Lyk6gVU7msSBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBC9nbxixDBzWyPZpr5xLrl9w7r0dgA4f3GN26Y55repz6Qn2qif9ycsqF6ZddvYnFM8kDEBBlo537cz9tMr3jh6zlh93V/5J2fiCW8cvTXhXyuLG/xrYeZmv7+Xt6Zf98yd6ZqM1lj7mgzd2UWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFguhpUQ1r5hbN/MmW6eT2P5044x7n2PhWt81bv/PbNMacwg5nxRgAQM4EC16bjH0Y/Akuylg1JmtiipxVY5z9ZK3kMuIXqXAsYzUXp6imMeEXzCxO+P2dvck/d7Nb04VPt2x7P7n9/ZH2RWu6s4sEobCLBKGwiwShsIsEobCLBKGwiwShsIsEobCLBNHTohoAgKULCxaa6eKE9+bXuYc4P+evzlGd9QscqgtOoUojYxUWy1jNxVPJ+J7cLGdFGLdopoSCGcAvmslZyYUjieVPCrbOvxYaziwz8zf4x5nb4BfVNP36HncyoUtz6Z00EzMW6c4uEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEkRPx9ltsYLGdHrc882ZLcntv61tdo/Dc/646Lopfyx49GJ69ZrKQno7AKCVMf7tjm3njFv737fNqXEAADiTV5Qxhg4A8NrUMy7NjIkpGhv91Vwu35a+Ji9t889tK6O7Lf+yRP1C+lhXTm5IH2Oh/XnVnV0kCDfsJLeR/BnJX5N8neQjxfObSL5I8q3i48bV766IdCrnzt4A8HUz2wHgMwAeIrkDwH4AR8xsO4AjxeciMqDcsJvZlJm9Ujy+BOANALcC2APgUNHsEID7V6uTItK96/qZneTtAD4F4JcANpvZVLHpDIAVf3NGch/JSZKTzctXuuiqiHQjO+wk1wH4MYCvmdnF5dvMzICV5zI2swNmtsvMdlXXre2qsyLSuaywk6xjKeg/MLOfFE+fJbml2L4FQHrCdxHpq5zfxhPAEwDeMLNvL9t0GMDe4vFeAM+W3z0RKUtOUc1nAfwDgNdIHiue+waAbwF4muRXALwD4AFvR5UFYN3/pb+/WDVdecCMOpb6FX/CiPH3nVkCANQvLKYbNPx9uMUjAFB3XrO/B1jGBBc5+3H3kVHgk1N4402CkTUxxbhfVDNzi7+ay9S96f/Hv/v0y+4+/mvqDrfNByc2uW1Gz6XPS+1s+txWEpesG3Yz+wXaXyef875eRAaDKuhEglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFgujpTDWVBjA+3d0KKfVZf+aX6rx/jPplvzqnOusU1eSs9pIxgwxr6cIbg19gwlpJq9N4RTM5K8JkcGfWGfVfc2u07raZ3eT392/vOpbc/t1bXnL38fiaM26bx879jduG0+kioLrzt2RMXAa6s4sEobCLBKGwiwShsIsEobCLBKGwiwShsIsEobCLBNHTohoaUF1MF3akigKAvIIZNvw2ljHjSmvUOT1MLxsEAFzMKIhpOC86Zwkpb9mmXCUsRZWjVXNmLBrxL83Gev/cVjJmNvrXV//Mb+T4+ek73Tb1U/7MOtX59PaKk5+Vp30tvtY9uoh8JCjsIkEo7CJBKOwiQSjsIkEo7CJBKOwiQfR2nL1pqF9OjxnTGS+uzvljzpVmxrh0M2Nc2muSMeZszngy4K/mwpxJJ3La5ChjHL2MSTIy/n8qc/6KPGum/TY3/Hd6Eoz//O2n/b4485wAwLqMlYq8OpKxD9KvJzUOrzu7SBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBAKu0gQtLKKMXIORv4OwDvLnroRwHs960D3hqm/w9RXYLj6O8h9/WMzu2mlDT0N+x8cnJw0s11968B1Gqb+DlNfgeHq7zD1dTm9jRcJQmEXCaLfYT/Q5+Nfr2Hq7zD1FRiu/g5TXz/U15/ZRaR3+n1nF5EeUdhFguhb2EneR/JNkidI7u9XP3KQPEnyNZLHSE72uz/XInmQ5DTJ48ue20TyRZJvFR839rOPy7Xp7zdJni7O8TGSX+xnH68iuY3kz0j+muTrJB8pnh/Y89tOX8JOsgrgcQBfALADwIMkd/SjL9fhXjPbOaDjq08CuO+a5/YDOGJm2wEcKT4fFE/iD/sLAN8pzvFOM3uux31qpwHg62a2A8BnADxUXKuDfH5X1K87+90ATpjZ22a2AOBHAPb0qS9Dz8yOAjh3zdN7ABwqHh8CcH9PO5XQpr8DycymzOyV4vElAG8AuBUDfH7b6VfYbwXw7rLPTxXPDSoD8ALJl0nu63dnMm02s6ni8RkAm/vZmUwPk3y1eJs/cG+LSd4O4FMAfokhPL/6BV2ee8zsLiz92PEQyb/qd4euhy2Nrw76GOv3AHwcwE4AUwAe6293fh/JdQB+DOBrZnZx+bYhOb99C/tpANuWfb61eG4gmdnp4uM0gGew9GPIoDtLcgsAFB+n+9yfJDM7a2ZNM2sB+D4G6ByTrGMp6D8ws58UTw/V+QX6F/aXAGwneQfJEQBfBnC4T31JIrmW5PqrjwF8HsDx9FcNhMMA9haP9wJ4to99cV0NTuFLGJBzTJIAngDwhpl9e9mmoTq/QB8r6IqhlX8GUAVw0Mz+qS8dcZC8E0t3c2Bpnv0fDlpfST4FYDeW/vTyLIBHAfwUwNMAbsPSnxU/YGYD8UuxNv3djaW38AbgJICvLvuZuG9I3gPg5wBeA3B1QYJvYOnn9oE8v+2oXFYkCP2CTiQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSSI/wdiil05NQ4ghAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_h1hm9HOBMW"
      },
      "source": [
        "# use test set to evaluate\n",
        "n = 5\n",
        "x_test = train_df[train_df.delta == n].iloc[:, 1:626].values.reshape(-1, 25, 25, 1)\n",
        "y_test = train_df[train_df.delta == n].iloc[:, 626:].values.reshape(-1, 25, 25, 1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9YhBmnqRypZ",
        "outputId": "3d2d2cb8-fc19-4e77-b338-fcdfc016b1eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "models[n-1].evaluate(x_test, y_test, batch_size=512)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 17s 863ms/step - loss: 1.0531 - accuracy: 0.8602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0531296730041504, 0.8602374792098999]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWvayna9SF-h"
      },
      "source": [
        "# submission data set\n",
        "submit_df = pd.DataFrame(index=test_df.index, columns=['start_' + str(_) for _ in range(0, 625)])\n",
        "\n",
        "for delta in range(1, 6):\n",
        "    mod = models[delta-1]\n",
        "    delta_df = test_df[test_df.delta == delta].iloc[:, 1:].values.reshape(-1, 25, 25, 1)\n",
        "    submit_df[test_df.delta == delta] = mod.predict(delta_df).reshape(-1, 625).round(0).astype('uint8')\n",
        "    \n",
        "submit_df.to_csv('submission.csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9iAZve2U_tD"
      },
      "source": [
        "submit_df = pd.read_csv('submission.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}